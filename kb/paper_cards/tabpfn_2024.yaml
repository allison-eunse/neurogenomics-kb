title: "TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second"
short_name: "TabPFN"
authors:
  - Noah Hollmann
  - Samuel Müller
  - Katharina Eggensperger
  - Frank Hutter
year: 2023
venue: "ICLR 2023"
pdf_source: "https://arxiv.org/pdf/2207.01848"
doi: "arXiv:2207.01848"
local_pdf_path: "docs/generated/kb_curated/papers-pdf/tabpfn_2024.pdf"
summary_md_path: "docs/generated/kb_curated/papers-md/tabpfn_2024.md"

summary: |
  TabPFN is an 11M-parameter tabular foundation model that uses a decoder-only Transformer trained on 100M synthetic datasets generated from structural causal models to emulate Bayesian inference for small/medium tabular problems in a single forward pass. Unlike traditional ML methods that require training on each dataset, TabPFN performs in-context learning: given a new tabular dataset (up to 10,000 samples, 500 features), it predicts labels for unlabeled rows in one forward pass without gradient updates. This enables extremely fast inference (~1 second) while achieving competitive or superior performance to gradient-boosted decision trees and neural networks.

key_contributions:
  - "In-context learning for tabular data: predict entire dataset labels in single forward pass"
  - "Training on 100M synthetic SCM-based datasets: learns diverse tabular patterns"
  - "Fast inference: ~1 second for datasets up to 10k samples (vs. minutes/hours for GBDT/NN training)"
  - "Handles categorical + continuous features with missing value support"
  - "Competitive with or outperforms GBDT/NN baselines on small/medium tabular benchmarks"

model:
  name: "TabPFN"
  backbone: "Decoder-only Transformer"
  architecture: "Transformer trained on synthetic structural causal models"
  modalities:
    - tabular
  parameter_scale: "11M"
  context_length: "10,000 samples"
  special_features:
    - "In-context learning: no gradient updates at inference"
    - "Supports up to 500 features (categorical + continuous)"
    - "Missing value handling via mask tokens"
    - "Probabilistic predictions (class probabilities, regression means)"

implications_for_project:
  - "Baseline predictor on raw sMRI ROI tables (smri_free_surfer_raw_176)"
  - "Baseline predictor on genetics summary features (PGS, PCA)"
  - "Fusion predictor on concatenated gene + brain embeddings (fusion_concat_gene_brain_1024_v1)"
  - "Fast prototyping tool: test gene-brain fusion hypotheses quickly before full GBDT/NN training"
  - "Compare TabPFN vs. LR/GBDT on late fusion baselines"
  - "Limitation: UK Biobank N~40k requires chunking (max 10k samples per forward pass)"

related_to:
  - "docs/generated/kb_curated/papers-md/tabpfn_2024.md"
  - "kb/model_cards/tabpfn.yaml"
  - "docs/integration/analysis_recipes/prediction_baselines.md"
  - "docs/integration/integration_strategy.md"
  - "configs/experiments/03_prediction_baselines_tabular.yaml"

verification_status: "needs_human_review"
notes: "TabPFN is highly relevant for fast late fusion prototyping. Treat as downstream predictor competing with LR/GBDT on embeddings. Keep per-fold sample counts ≤10k or batch inference."

tags:
  - tabular
  - foundation_model
  - in_context_learning
  - transformer
  - bayesian_inference
  - fast_inference
  - baseline_predictor

